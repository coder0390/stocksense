{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-11T12:13:30.097229Z","iopub.status.busy":"2024-07-11T12:13:30.096786Z","iopub.status.idle":"2024-07-11T12:14:15.217775Z","shell.execute_reply":"2024-07-11T12:14:15.216683Z","shell.execute_reply.started":"2024-07-11T12:13:30.097196Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n","Collecting accelerate\n","  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n","Collecting peft\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\n","Collecting transformers\n","  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n","Collecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.4)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.3.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: pyarrow, einops, bitsandbytes, accelerate, transformers, datasets, peft\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.30.1\n","    Uninstalling accelerate-0.30.1:\n","      Successfully uninstalled accelerate-0.30.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.41.2\n","    Uninstalling transformers-4.41.2:\n","      Successfully uninstalled transformers-4.41.2\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.19.2\n","    Uninstalling datasets-2.19.2:\n","      Successfully uninstalled datasets-2.19.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 24.4.1 requires cubinlinker, which is not installed.\n","cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 24.4.1 requires ptxcompiler, which is not installed.\n","cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n","beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\n","cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n","cudf 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n","rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.32.1 bitsandbytes-0.43.1 datasets-2.20.0 einops-0.8.0 peft-0.11.1 pyarrow-16.1.0 transformers-4.42.3\n"]}],"source":["!pip install -U accelerate peft transformers einops datasets bitsandbytes"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-07T11:32:33.950977Z","iopub.status.busy":"2024-07-07T11:32:33.950301Z","iopub.status.idle":"2024-07-07T11:32:35.934741Z","shell.execute_reply":"2024-07-07T11:32:35.933572Z","shell.execute_reply.started":"2024-07-07T11:32:33.950944Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement cuda (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for cuda\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T07:05:45.445417Z","iopub.status.busy":"2024-07-08T07:05:45.445096Z","iopub.status.idle":"2024-07-08T07:05:57.641943Z","shell.execute_reply":"2024-07-08T07:05:57.641158Z","shell.execute_reply.started":"2024-07-08T07:05:45.445388Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-07-08 07:05:47.306374: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-08 07:05:47.306477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-08 07:05:47.436145: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from transformers import set_seed\n","\n","set_seed(42)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T07:08:06.754704Z","iopub.status.busy":"2024-07-08T07:08:06.754010Z","iopub.status.idle":"2024-07-08T07:08:07.249681Z","shell.execute_reply":"2024-07-08T07:08:07.248222Z","shell.execute_reply.started":"2024-07-08T07:08:06.754668Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bf90c187371d4e8e886cf184d749df01","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"Failed to import transformers.models.mega.configuration_mega because of the following error (look up to see its traceback):\nNo module named 'transformers.models.mega.configuration_mega'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1535\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;66;03m# Needed for autocompletion in an IDE\u001b[39;00m\n\u001b[0;32m-> 1535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__dir__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1536\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__dir__\u001b[39m()\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models.mega.configuration_mega'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m modelpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/phi-2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBitsAndBytesConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbnb_4bit_compute_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbnb_4bit_quant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnf4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# FA2 does not work yet\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# attn_implementation=\"flash_attention_2\",          \u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:540\u001b[0m, in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    538\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs_orig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 540\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map\n\u001b[1;32m    541\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    542\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m resolve_trust_remote_code(\n\u001b[1;32m    543\u001b[0m     trust_remote_code, pretrained_model_name_or_path, has_local_code, has_remote_code\n\u001b[1;32m    544\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:751\u001b[0m, in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m getattribute_from_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name], attr)\n\u001b[0;32m--> 751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeys\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    752\u001b[0m     mapping_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, name)\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_keys \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content\u001b[38;5;241m.\u001b[39mkeys())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:752\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeys\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 752\u001b[0m     mapping_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, name)\n\u001b[1;32m    754\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    756\u001b[0m     ]\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_keys \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content\u001b[38;5;241m.\u001b[39mkeys())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:748\u001b[0m, in \u001b[0;36m_load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    746\u001b[0m module_name \u001b[38;5;241m=\u001b[39m model_type_to_module_name(model_type)\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m--> 748\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m getattribute_from_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name], attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:692\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, attr):\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1525\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1523\u001b[0m     for value in values:\n\u001b[1;32m   1524\u001b[0m         self._class_to_module[value] = key\n\u001b[0;32m-> 1525\u001b[0m # Needed for autocompletion in an IDE\n\u001b[1;32m   1526\u001b[0m self.__all__ = list(import_structure.keys()) + list(chain(*import_structure.values()))\n\u001b[1;32m   1527\u001b[0m self.__file__ = module_file\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/import_utils.py:1537\u001b[0m, in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1535\u001b[0m def __dir__(self):\n\u001b[1;32m   1536\u001b[0m     result = super().__dir__()\n\u001b[0;32m-> 1537\u001b[0m     # The elements of self.__all__ that are submodules may or may not be in the dir already, depending on whether\n\u001b[1;32m   1538\u001b[0m     # they have been accessed or not. So we only add the elements of self.__all__ that are not already in the dir.\n\u001b[1;32m   1539\u001b[0m     for attr in self.__all__:\n\u001b[1;32m   1540\u001b[0m         if attr not in result:\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.mega.configuration_mega because of the following error (look up to see its traceback):\nNo module named 'transformers.models.mega.configuration_mega'"]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n","\n","# Load model\n","modelpath = \"microsoft/phi-2\"\n","model = AutoModelForCausalLM.from_pretrained(\n","    modelpath,    \n","    device_map=\"auto\",\n","    quantization_config=BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_compute_dtype=torch.bfloat16,\n","        bnb_4bit_quant_type=\"nf4\",\n","    ),\n","    torch_dtype=torch.bfloat16,\n","    # FA2 does not work yet\n","    # attn_implementation=\"flash_attention_2\",          \n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-07-08T07:04:44.591382Z","iopub.status.idle":"2024-07-08T07:04:44.591685Z","shell.execute_reply":"2024-07-08T07:04:44.591542Z","shell.execute_reply.started":"2024-07-08T07:04:44.591530Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(modelpath, use_fast=False)    # fast tokenizer sometimes ignores the added tokens"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T07:11:07.474716Z","iopub.status.busy":"2024-07-08T07:11:07.473566Z","iopub.status.idle":"2024-07-08T07:12:25.753049Z","shell.execute_reply":"2024-07-08T07:12:25.752013Z","shell.execute_reply.started":"2024-07-08T07:11:07.474677Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe91d5f5cf9847c6ad8ff30f635713a2","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/735 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9adb1f064ed042bebe28701079506664","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/35.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d7fb15d4d9d24ee887bb31997861c441","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"49af2215fa72471480fdfec11f800eb8","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"887f30b2fbd84395b3c9871b6a254ab9","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b9fafcabb5a468d8ded5e8ba1fc7c74","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e03f54ebc6d4413b4b60e8acd0f72b2","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7fe41adf2b094ba292fdbc1e32745783","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6197016dab644cab5812f97e6b7179f","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"660025bf242f45c0b9640ec51630f565","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c82cf707a0af4529a67dabe602f1ea6e","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93111a9fac1d42b8a823ab64cedfa3d3","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f1cb02f712c4297a5e668a44e3de414","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["#Copied and modified from https://github.com/geronimi73/phi2-finetune/blob/main/nb_qlora.ipynb\n","from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n","from peft import PeftModel\n","import torch\n","\n","# base model\n","base_path=\"microsoft/phi-2\"  \n","\n","# adapters: path to folder with adapter_model.safetensors\n","adapter_path=\"/kaggle/input/notebook2cdf301890/out/checkpoint-564\" \n","\n","# where to save merged model\n","save_to=\"trained_model\"       \n","\n","# Load model and tokenizer\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_path,\n","    torch_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n",")\n","tokenizer = AutoTokenizer.from_pretrained(base_path)\n","\n","# Add/set tokens same tokens to base model before merging, like we did before training  \n","tokenizer.add_tokens([\"<|im_start|>\", \"<PAD>\"])\n","tokenizer.pad_token = \"<PAD>\"\n","tokenizer.add_special_tokens(dict(eos_token=\"<|im_end|>\"))\n","\n","# Add ChatML template to tokenizer\n","tokenizer.chat_template=\"{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\"\n","\n","base_model.config.eos_token_id = tokenizer.eos_token_id\n","\n","# Set a default Generation configuration: Llama precise\n","generation_config = GenerationConfig(\n","    max_new_tokens=100, \n","    temperature=0.7,\n","    top_p=0.1,\n","    top_k=40,\n","    repetition_penalty=1.18,\n","    do_sample=True,\n","    pad_token_id=tokenizer.pad_token_id,\n","    eos_token_id=tokenizer.eos_token_id,\n",")\n","\n","# Load LoRA and merge\n","model = PeftModel.from_pretrained(base_model, adapter_path)\n","model = model.merge_and_unload()\n","\n","model.save_pretrained(save_to, safe_serialization=True, max_shard_size='4GB')\n","tokenizer.save_pretrained(save_to)\n","generation_config.save_pretrained(save_to)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:18:34.382725Z","iopub.status.busy":"2024-07-11T12:18:34.381734Z","iopub.status.idle":"2024-07-11T12:20:16.030623Z","shell.execute_reply":"2024-07-11T12:20:16.029575Z","shell.execute_reply.started":"2024-07-11T12:18:34.382691Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["/bin/bash: line 0: fg: no job control\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b003a091adfa41c69652bbddbe5a2613","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/218 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","2024-07-11 12:18:45.299953: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-11 12:18:45.300071: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-11 12:18:45.436565: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["I am a language model artificial intelligence designed to help answer questions and provide information. I don't have a physical body or personal identity like humans do. If there's anything specific you'd like me to know or discuss, please let me know!\n"]}],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n","from peft import PeftModel\n","import torch\n","!%%time\n","model_path=\"Haotianl/finephi2\"    \n","question=\"Hello, who are you?\"\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","        model_path,    \n","        #torch_dtype=torch.bfloat16,\n","        device_map=\"auto\"\n","    )\n","tokenizer = AutoTokenizer.from_pretrained(model_path) \n","\n","messages=[\n","    {\"role\": \"user\", \"content\": question}\n","]\n","        \n","input_tokens = tokenizer.apply_chat_template(\n","    messages, \n","    add_generation_prompt=True,\n","    return_tensors=\"pt\"\n",").to(\"cuda\")\n","\n","output_tokens = model.generate(input_tokens)\n","output = tokenizer.decode(\n","    output_tokens[0][len(input_tokens[0]):],\n","    skip_special_tokens=True\n","    )               \n","\n","print(output)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:50:55.595875Z","iopub.status.busy":"2024-07-11T12:50:55.595020Z","iopub.status.idle":"2024-07-11T12:51:08.922896Z","shell.execute_reply":"2024-07-11T12:51:08.921905Z","shell.execute_reply.started":"2024-07-11T12:50:55.595842Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.2)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n"]}],"source":["!pip install huggingface_hub"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:51:10.809195Z","iopub.status.busy":"2024-07-11T12:51:10.808365Z","iopub.status.idle":"2024-07-11T12:51:11.088511Z","shell.execute_reply":"2024-07-11T12:51:11.087857Z","shell.execute_reply.started":"2024-07-11T12:51:10.809163Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"218ef81afd8e42d5bf2cf696dc5769f1","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","#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\n","\n","notebook_login()"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T07:30:25.775108Z","iopub.status.busy":"2024-07-08T07:30:25.774545Z","iopub.status.idle":"2024-07-08T07:32:28.325644Z","shell.execute_reply":"2024-07-08T07:32:28.324530Z","shell.execute_reply.started":"2024-07-08T07:30:25.775073Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://download.pytorch.org/whl/nightly/cu118\n","Collecting torch==2.2.0.dev20231010+cu118\n","  Downloading https://download.pytorch.org/whl/nightly/cu118/torch-2.2.0.dev20231010%2Bcu118-cp310-cp310-linux_x86_64.whl (2475.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 GB\u001b[0m \u001b[31m406.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0.dev20231010+cu118) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0.dev20231010+cu118) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0.dev20231010+cu118) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0.dev20231010+cu118) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0.dev20231010+cu118) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0.dev20231010+cu118) (2024.3.1)\n","Collecting pytorch-triton==2.1.0+6e4932cda8 (from torch==2.2.0.dev20231010+cu118)\n","  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-2.1.0%2B6e4932cda8-cp310-cp310-linux_x86_64.whl (125.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.0.dev20231010+cu118) (2.1.3)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.0.dev20231010+cu118) (1.3.0)\n","Installing collected packages: pytorch-triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","Successfully installed pytorch-triton-2.1.0+6e4932cda8 torch-2.2.0.dev20231010+cu118\n"]}],"source":["!pip install --index-url https://download.pytorch.org/whl/nightly/cu118 --pre 'torch==2.2.0.dev20231010+cu118'"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T07:15:48.344285Z","iopub.status.busy":"2024-07-08T07:15:48.343610Z","iopub.status.idle":"2024-07-08T07:16:28.828328Z","shell.execute_reply":"2024-07-08T07:16:28.826947Z","shell.execute_reply.started":"2024-07-08T07:15:48.344254Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8412ca5bb1be4ab69c8454fd455922f5","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2525: UserWarning: Attempting to save a model with offloaded modules. Ensure that unallocated cpu memory exceeds the `shard_size` (5GB default)\n","  warnings.warn(\n"]},{"ename":"HfHubHTTPError","evalue":" (Request ID: Root=1-668b924b-1133be2b5de480440c6bada8;88d2aaa5-e897-4d4d-88a7-746678ae960f)\n\n403 Forbidden: Forbidden: you must use a write token to upload to a repository..\nCannot access content at: https://huggingface.co/api/models/Haotianl/finephi2-v1.1/preupload/main.\nIf you are trying to create or update content,make sure you have a token with the `write` role.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/Haotianl/finephi2-v1.1/preupload/main","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(modelpath) \n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Upload\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHaotianl/finephi2-v1.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHaotianl/finephi2-v1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2735\u001b[0m, in \u001b[0;36mPreTrainedModel.push_to_hub\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags:\n\u001b[1;32m   2734\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tags\n\u001b[0;32m-> 2735\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:935\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# Update model card if needed:\u001b[39;00m\n\u001b[1;32m    933\u001b[0m model_card\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(work_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mREADME.md\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 935\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_modified_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_timestamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:799\u001b[0m, in \u001b[0;36mPushToHubMixin._upload_modified_files\u001b[0;34m(self, working_dir, repo_id, files_timestamps, commit_message, token, create_pr, revision, commit_description)\u001b[0m\n\u001b[1;32m    796\u001b[0m     create_branch(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, branch\u001b[38;5;241m=\u001b[39mrevision, token\u001b[38;5;241m=\u001b[39mtoken, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    798\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading the following files to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(modified_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 799\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_commit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:1286\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_as_future(fn, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:3677\u001b[0m, in \u001b[0;36mHfApi.create_commit\u001b[0;34m(self, repo_id, operations, commit_message, commit_description, token, repo_type, revision, create_pr, num_threads, parent_commit, run_as_future)\u001b[0m\n\u001b[1;32m   3674\u001b[0m \u001b[38;5;66;03m# If updating twice the same file or update then delete a file in a single commit\u001b[39;00m\n\u001b[1;32m   3675\u001b[0m _warn_on_overwriting_operations(operations)\n\u001b[0;32m-> 3677\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreupload_lfs_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munquoted_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# first-class methods take unquoted revision\u001b[39;49;00m\n\u001b[1;32m   3683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfree_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# do not remove `CommitOperationAdd.path_or_fileobj` on LFS files for \"normal\" users\u001b[39;49;00m\n\u001b[1;32m   3686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3687\u001b[0m files_to_copy \u001b[38;5;241m=\u001b[39m _fetch_files_to_copy(\n\u001b[1;32m   3688\u001b[0m     copies\u001b[38;5;241m=\u001b[39mcopies,\n\u001b[1;32m   3689\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3693\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m   3694\u001b[0m )\n\u001b[1;32m   3695\u001b[0m commit_payload \u001b[38;5;241m=\u001b[39m _prepare_commit_payload(\n\u001b[1;32m   3696\u001b[0m     operations\u001b[38;5;241m=\u001b[39moperations,\n\u001b[1;32m   3697\u001b[0m     files_to_copy\u001b[38;5;241m=\u001b[39mfiles_to_copy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3700\u001b[0m     parent_commit\u001b[38;5;241m=\u001b[39mparent_commit,\n\u001b[1;32m   3701\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:4153\u001b[0m, in \u001b[0;36mHfApi.preupload_lfs_files\u001b[0;34m(self, repo_id, additions, token, repo_type, revision, create_pr, num_threads, free_memory, gitignore_content)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;66;03m# Check which new files are LFS\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4153\u001b[0m     \u001b[43m_fetch_upload_modes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4154\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_additions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_pr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_pr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgitignore_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgitignore_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   4164\u001b[0m     e\u001b[38;5;241m.\u001b[39mappend_to_message(_CREATE_COMMIT_NO_REPO_ERROR_MESSAGE)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/_commit_api.py:508\u001b[0m, in \u001b[0;36m_fetch_upload_modes\u001b[0;34m(additions, repo_type, repo_id, headers, revision, endpoint, create_pr, gitignore_content)\u001b[0m\n\u001b[1;32m    500\u001b[0m     payload[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgitIgnore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m gitignore_content\n\u001b[1;32m    502\u001b[0m resp \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/preupload/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    504\u001b[0m     json\u001b[38;5;241m=\u001b[39mpayload,\n\u001b[1;32m    505\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    506\u001b[0m     params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_pr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;28;01mif\u001b[39;00m create_pr \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    507\u001b[0m )\n\u001b[0;32m--> 508\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m preupload_info \u001b[38;5;241m=\u001b[39m _validate_preupload_info(resp\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    510\u001b[0m upload_modes\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]: file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muploadMode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m preupload_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:367\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mHfHubHTTPError\u001b[0m:  (Request ID: Root=1-668b924b-1133be2b5de480440c6bada8;88d2aaa5-e897-4d4d-88a7-746678ae960f)\n\n403 Forbidden: Forbidden: you must use a write token to upload to a repository..\nCannot access content at: https://huggingface.co/api/models/Haotianl/finephi2-v1.1/preupload/main.\nIf you are trying to create or update content,make sure you have a token with the `write` role."]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","#from transformers import \n","\n","# Load model and tokenizer\n","modelpath=\"trained_model\"\n","model = AutoModelForCausalLM.from_pretrained(\n","    modelpath,\n","    device_map=\"auto\",\n","    torch_dtype=torch.bfloat16,\n",")\n","tokenizer = AutoTokenizer.from_pretrained(modelpath) \n","\n","# Upload\n","model.push_to_hub(\"Haotianl/finephi2-v1.1\")\n","tokenizer.push_to_hub(\"Haotianl/finephi2-v1.1\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:51:26.222174Z","iopub.status.busy":"2024-07-11T12:51:26.221807Z","iopub.status.idle":"2024-07-11T12:51:29.869860Z","shell.execute_reply":"2024-07-11T12:51:29.868760Z","shell.execute_reply.started":"2024-07-11T12:51:26.222146Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'lm-evaluation-harness'...\n","remote: Enumerating objects: 38065, done.\u001b[K\n","remote: Counting objects: 100% (1664/1664), done.\u001b[K\n","remote: Compressing objects: 100% (723/723), done.\u001b[K\n","remote: Total 38065 (delta 1094), reused 1437 (delta 928), pack-reused 36401\u001b[K\n","Receiving objects: 100% (38065/38065), 24.34 MiB | 20.84 MiB/s, done.\n","Resolving deltas: 100% (26574/26574), done.\n"]}],"source":["!git clone https://github.com/EleutherAI/lm-evaluation-harness"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:51:31.370796Z","iopub.status.busy":"2024-07-11T12:51:31.370065Z","iopub.status.idle":"2024-07-11T12:52:10.597175Z","shell.execute_reply":"2024-07-11T12:52:10.596037Z","shell.execute_reply.started":"2024-07-11T12:51:31.370748Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Obtaining file:///kaggle/working/lm-evaluation-harness\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n","\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (0.30.1)\n","Collecting evaluate (from lm_eval==0.4.3)\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (2.19.2)\n","Collecting jsonlines (from lm_eval==0.4.3)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (2.10.0)\n","Collecting peft>=0.2.0 (from lm_eval==0.4.3)\n","  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (2.12.0)\n","Collecting pytablewriter (from lm_eval==0.4.3)\n","  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n","Collecting rouge-score>=0.0.4 (from lm_eval==0.4.3)\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting sacrebleu>=1.5.0 (from lm_eval==0.4.3)\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (1.2.2)\n","Collecting sqlitedict (from lm_eval==0.4.3)\n","  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (2.1.2)\n","Collecting tqdm-multiprocess (from lm_eval==0.4.3)\n","  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: transformers>=4.1 in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (4.41.2)\n","Requirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (0.19.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (0.3.8)\n","Collecting word2number (from lm_eval==0.4.3)\n","  Downloading word2number-1.1.zip (9.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from lm_eval==0.4.3) (10.2.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.23.2)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.26.0->lm_eval==0.4.3) (0.4.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.2.1)\n","Requirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets>=2.16.0->lm_eval==0.4.3) (2024.3.1)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm_eval==0.4.3) (3.9.1)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (3.2.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score>=0.0.4->lm_eval==0.4.3) (1.16.0)\n","Collecting portalocker (from sacrebleu>=1.5.0->lm_eval==0.4.3)\n","  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (0.9.0)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm_eval==0.4.3) (5.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm_eval==0.4.3) (3.2.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.3) (4.9.0)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.3) (1.12.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.3) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8->lm_eval==0.4.3) (3.1.2)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.1->lm_eval==0.4.3) (0.19.1)\n","Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->lm_eval==0.4.3) (23.2.0)\n","Requirement already satisfied: setuptools>=38.3.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm_eval==0.4.3) (69.0.3)\n","Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.4.3)\n","  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n","Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.4.3)\n","  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n","Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.4.3)\n","  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\n","Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.4.3)\n","  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n","Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.4.3)\n","  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n","Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3)\n","  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.3) (4.0.3)\n","Collecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.3)\n","  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.26.0->lm_eval==0.4.3) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->lm_eval==0.4.3) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->lm_eval==0.4.3) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->lm_eval==0.4.3) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets>=2.16.0->lm_eval==0.4.3) (2024.2.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2018.9 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.3) (2023.3.post1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8->lm_eval==0.4.3) (2.1.3)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=2.16.0->lm_eval==0.4.3) (2023.4)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8->lm_eval==0.4.3) (1.3.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n","Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n","Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n","Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n","Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n","Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n","Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n","Downloading portalocker-2.10.0-py3-none-any.whl (18 kB)\n","Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: lm_eval, rouge-score, sqlitedict, word2number\n","  Building editable for lm_eval (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for lm_eval: filename=lm_eval-0.4.3-0.editable-py3-none-any.whl size=17834 sha256=1ebe15028290ba309248db65979b85f8df29aaed109168249f440f645e264b7e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wuindrl1/wheels/1b/1a/1b/44c80ddb18c9d7d3ce79a8d6d4561bddaddcbffb4cdfbf3259\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=816160eaca8ba4783a31f8cfd86015442f4387bdeb636274e887f601eaa42c43\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=7fd9e0e97e03372e63ae1ca2124d461bb352b3d7ea46390b6d71c17f76b0be4c\n","  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n","  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=b16fe39a67f693d6e76242a0655a37643ea39f4fa80cd5abade96cb6d4200f15\n","  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n","Successfully built lm_eval rouge-score sqlitedict word2number\n","Installing collected packages: word2number, sqlitedict, tqdm-multiprocess, tcolorpy, portalocker, pathvalidate, jsonlines, chardet, sacrebleu, rouge-score, mbstrdecoder, typepy, peft, evaluate, DataProperty, tabledata, pytablewriter, lm_eval\n","Successfully installed DataProperty-1.0.1 chardet-5.2.0 evaluate-0.4.2 jsonlines-4.0.0 lm_eval-0.4.3 mbstrdecoder-1.1.3 pathvalidate-3.2.0 peft-0.11.1 portalocker-2.10.0 pytablewriter-1.2.0 rouge-score-0.1.2 sacrebleu-2.4.2 sqlitedict-2.1.0 tabledata-1.3.3 tcolorpy-0.1.6 tqdm-multiprocess-0.0.11 typepy-1.3.2 word2number-1.1\n"]}],"source":["import os\n","os.chdir('/kaggle/working/lm-evaluation-harness')\n","!pip install -e ."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-08T07:37:37.991325Z","iopub.status.busy":"2024-07-08T07:37:37.990505Z","iopub.status.idle":"2024-07-08T07:37:39.997900Z","shell.execute_reply":"2024-07-08T07:37:39.996934Z","shell.execute_reply.started":"2024-07-08T07:37:37.991287Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: -c: line 0: syntax error near unexpected token `False'\n","/bin/bash: -c: line 0: `torch.backends.cuda.enable_mem_efficient_sdp(False)'\n","/bin/bash: -c: line 0: syntax error near unexpected token `False'\n","/bin/bash: -c: line 0: `torch.backends.cuda.enable_flash_sdp(False)'\n"]}],"source":["!torch.backends.cuda.enable_mem_efficient_sdp(False)\n","!torch.backends.cuda.enable_flash_sdp(False)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:07:11.834792Z","iopub.status.busy":"2024-07-11T12:07:11.833863Z","iopub.status.idle":"2024-07-11T12:08:18.882344Z","shell.execute_reply":"2024-07-11T12:08:18.881355Z","shell.execute_reply.started":"2024-07-11T12:07:11.834755Z"},"trusted":true},"outputs":[],"source":["!lm_eval --model hf \\\n","    --model_args pretrained=microsoft/phi-2 \\\n","    --tasks arc_easy \\\n","    --device cuda:0 \\\n","    --batch_size 8"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T13:28:18.192832Z","iopub.status.busy":"2024-07-11T13:28:18.192425Z","iopub.status.idle":"2024-07-11T13:32:14.479337Z","shell.execute_reply":"2024-07-11T13:32:14.478168Z","shell.execute_reply.started":"2024-07-11T13:28:18.192800Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-07-11 13:28:23.004257: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-11 13:28:23.004311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-11 13:28:23.005809: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","100%|██████████████████████████████████████| 1172/1172 [00:01<00:00, 902.85it/s]\n","Running loglikelihood requests: 100%|███████| 4687/4687 [02:56<00:00, 26.61it/s]\n","hf (pretrained=Haotianl/finephi2,dtype=float), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 8\n","|    Tasks    |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n","|-------------|------:|------|-----:|--------|---|-----:|---|-----:|\n","|arc_challenge|      1|none  |     0|acc     |↑  |0.4872|±  |0.0146|\n","|             |       |none  |     0|acc_norm|↑  |0.5077|±  |0.0146|\n","\n"]}],"source":["\n","!lm_eval --model hf \\\n","    --model_args pretrained=Haotianl/finephi2,dtype=\"float\" \\\n","    --tasks arc_challenge \\\n","    --device cuda:0 \\\n","    --batch_size 8"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-11T12:36:42.531326Z","iopub.status.busy":"2024-07-11T12:36:42.530590Z","iopub.status.idle":"2024-07-11T12:37:04.835065Z","shell.execute_reply":"2024-07-11T12:37:04.833833Z","shell.execute_reply.started":"2024-07-11T12:36:42.531288Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["2024-07-11 12:36:48.200938: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-11 12:36:48.201004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-11 12:36:48.202494: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["!lm-eval --tasks list"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":187132037,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
